<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ASCEND: Exploring Scale Effects in Medical Transformer Models</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #1a1a1a;
            background-color: #ffffff;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 0 20px;
        }
        
        header {
            padding: 60px 0 40px;
            text-align: center;
            border-bottom: 1px solid #e0e0e0;
        }
        
        h1 {
            font-size: 2.5em;
            font-weight: 600;
            margin-bottom: 20px;
            letter-spacing: -0.02em;
        }
        
        .subtitle {
            font-size: 1.2em;
            color: #666;
            max-width: 700px;
            margin: 0 auto 30px;
            line-height: 1.5;
        }
        
        .authors {
            font-size: 1.1em;
            color: #333;
            margin-bottom: 10px;
        }
        
        .affiliation {
            font-size: 0.95em;
            color: #666;
            font-style: italic;
        }
        
        nav {
            position: sticky;
            top: 0;
            background: #fff;
            border-bottom: 1px solid #e0e0e0;
            padding: 15px 0;
            z-index: 100;
            margin-bottom: 40px;
        }
        
        nav ul {
            list-style: none;
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 30px;
        }
        
        nav a {
            color: #666;
            text-decoration: none;
            font-size: 0.95em;
            transition: color 0.2s;
        }
        
        nav a:hover, nav a.active {
            color: #0066cc;
        }
        
        section {
            padding: 40px 0;
            border-bottom: 1px solid #e0e0e0;
        }
        
        section:last-child {
            border-bottom: none;
        }
        
        h2 {
            font-size: 1.8em;
            font-weight: 600;
            margin-bottom: 25px;
            letter-spacing: -0.01em;
        }
        
        h3 {
            font-size: 1.3em;
            font-weight: 600;
            margin: 30px 0 15px;
            color: #333;
        }
        
        p {
            margin-bottom: 18px;
            line-height: 1.7;
            color: #333;
        }
        
        .highlight-box {
            background: #f8f9fa;
            border-left: 4px solid #0066cc;
            padding: 20px 25px;
            margin: 30px 0;
            border-radius: 4px;
        }
        
        .highlight-box h4 {
            font-size: 1.1em;
            margin-bottom: 10px;
            color: #0066cc;
        }
        
        .figure {
            margin: 40px 0;
            text-align: center;
        }
        
        .figure img, .figure svg {
            max-width: 100%;
            height: auto;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            background: #fff;
        }
        
        .figure-caption {
            margin-top: 15px;
            font-size: 0.9em;
            color: #666;
            text-align: left;
            max-width: 700px;
            margin-left: auto;
            margin-right: auto;
            line-height: 1.5;
        }
        
        .figure-caption strong {
            color: #333;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 30px 0;
            font-size: 0.95em;
        }
        
        th, td {
            padding: 12px 16px;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }
        
        th {
            background: #f8f9fa;
            font-weight: 600;
            color: #333;
        }
        
        tr:hover {
            background: #f8f9fa;
        }
        
        .metric-card {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            margin: 20px 0;
        }
        
        .metric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        
        .metric-item {
            text-align: center;
            padding: 20px;
            background: white;
            border-radius: 8px;
            border: 1px solid #e0e0e0;
        }
        
        .metric-value {
            font-size: 2em;
            font-weight: 600;
            color: #0066cc;
            margin-bottom: 5px;
        }
        
        .metric-label {
            font-size: 0.9em;
            color: #666;
        }
        
        .code-block {
            background: #f6f8fa;
            border: 1px solid #e0e0e0;
            border-radius: 6px;
            padding: 20px;
            margin: 20px 0;
            font-family: 'SF Mono', Monaco, 'Cascadia Code', monospace;
            font-size: 0.9em;
            line-height: 1.5;
            overflow-x: auto;
        }
        
        .insight {
            background: #fff8e1;
            border-left: 4px solid #ffa000;
            padding: 20px 25px;
            margin: 30px 0;
            border-radius: 4px;
        }
        
        .insight strong {
            color: #f57c00;
        }
        
        .comparison-chart {
            width: 100%;
            height: 400px;
            margin: 30px 0;
            position: relative;
            background: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
        }
        
        .bar {
            display: inline-block;
            vertical-align: bottom;
            margin: 0 10px;
            position: relative;
            text-align: center;
        }
        
        .bar-inner {
            background: #0066cc;
            border-radius: 4px 4px 0 0;
            transition: all 0.3s;
        }
        
        .bar:hover .bar-inner {
            background: #0052a3;
        }
        
        .bar-label {
            position: absolute;
            bottom: -25px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 0.85em;
            white-space: nowrap;
        }
        
        .bar-value {
            position: absolute;
            top: -25px;
            left: 50%;
            transform: translateX(-50%);
            font-weight: 600;
            font-size: 0.9em;
        }
        
        footer {
            padding: 40px 0;
            text-align: center;
            color: #666;
            font-size: 0.9em;
            border-top: 1px solid #e0e0e0;
            margin-top: 60px;
        }
        
        @media (max-width: 768px) {
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; }
            .metric-grid { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>ASCEND: Exploring Scale Effects in Medical Transformer Models</h1>
            <p class="subtitle">An investigation into the relationship between model capacity and task-specific performance in clinical risk prediction using electronic health records</p>
            <p class="authors">ASCEND Research Team</p>
            <p class="affiliation">June 2025</p>
        </div>
    </header>
    
    <nav>
        <div class="container">
            <ul>
                <li><a href="#abstract" class="active">Abstract</a></li>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#methodology">Methodology</a></li>
                <li><a href="#experiments">Experiments</a></li>
                <li><a href="#results">Results</a></li>
                <li><a href="#insights">Insights</a></li>
                <li><a href="#future">Future Work</a></li>
            </ul>
        </div>
    </nav>
    
    <main class="container">
        <section id="abstract">
            <h2>Abstract</h2>
            <p>We present ASCEND (A Self-supervised Cardiovascular Events Neural Decoder), an investigation into the effects of model scale on medical sequence modeling tasks. Through careful experimentation with models ranging from 27M to 202M parameters, we explore a fundamental question in medical AI: does increased model capacity uniformly improve performance across all clinical prediction tasks?</p>
            
            <div class="highlight-box">
                <h4>Key Finding</h4>
                <p>Our experiments reveal that the relationship between model scale and performance is task-dependent. While our 202M parameter model achieved state-of-the-art mortality prediction (AUROC 0.932), it underperformed the smaller 27M model on rare event prediction tasks such as myocardial infarction and stroke.</p>
            </div>
            
            <p>This work demonstrates the viability of transformer-based approaches for medical sequence modeling while challenging the assumption that larger models universally outperform smaller ones in healthcare applications. Our findings suggest that optimal model architecture depends critically on the specific clinical task and data characteristics.</p>
        </section>
        
        <section id="introduction">
            <h2>Introduction</h2>
            
            <h3>Motivation</h3>
            <p>The success of large language models has led to a natural question: can similar scaling principles be applied to medical sequence modeling? Electronic health records (EHRs) contain rich temporal sequences of clinical events that could potentially benefit from the pattern recognition capabilities of transformer architectures.</p>
            
            <p>However, medical data presents unique challenges:</p>
            <ul style="margin: 20px 0; padding-left: 30px; line-height: 1.8;">
                <li><strong>Extreme class imbalance:</strong> Clinical events of interest often occur in less than 1% of the population</li>
                <li><strong>Irregular temporal sampling:</strong> Unlike text, medical events occur at irregular intervals</li>
                <li><strong>High dimensionality:</strong> Tens of thousands of possible medical codes and laboratory values</li>
                <li><strong>Mixed modalities:</strong> Combining discrete diagnoses, continuous lab values, and temporal patterns</li>
            </ul>
            
            <h3>Research Questions</h3>
            <p>This investigation addresses several key questions:</p>
            <ol style="margin: 20px 0; padding-left: 30px; line-height: 1.8;">
                <li>Can transformer architectures effectively model medical event sequences?</li>
                <li>Does increased model capacity improve performance uniformly across different clinical tasks?</li>
                <li>How do data characteristics (prevalence, complexity) interact with model scale?</li>
                <li>What are the practical implications for deploying medical AI systems?</li>
            </ol>
            
            <div class="insight">
                <strong>Why This Matters:</strong> Understanding the relationship between model scale and task performance is crucial for efficient resource allocation in medical AI development. If smaller models can match or exceed larger models on specific tasks, this has significant implications for deployment costs and accessibility.
            </div>
        </section>
        
        <section id="methodology">
            <h2>Methodology</h2>
            
            <h3>Dataset and Task Definition</h3>
            <p>We utilized de-identified EHR data from Stanford Healthcare containing 19,390 patients with comprehensive longitudinal records. Our approach focuses on predicting cardiovascular outcomes within a one-year horizon. Note that the enhanced dataset used for the large model contained only three individual outcomes plus a composite:</p>
            
            <table>
                <thead>
                    <tr>
                        <th>Outcome</th>
                        <th>Definition</th>
                        <th>Prevalence</th>
                        <th>Clinical Significance</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Mortality</td>
                        <td>All-cause death</td>
                        <td>0.85%</td>
                        <td>Primary endpoint for risk stratification</td>
                    </tr>
                    <tr>
                        <td>Myocardial Infarction</td>
                        <td>ICD codes I21.*, I22.*</td>
                        <td>0.34%</td>
                        <td>Major adverse cardiac event</td>
                    </tr>
                    <tr>
                        <td>Stroke</td>
                        <td>ICD codes I60-I66.*</td>
                        <td>0.32%</td>
                        <td>Cerebrovascular complication</td>
                    </tr>
                </tbody>
            </table>
            
            <div class="insight">
                <strong>Data Availability Note:</strong> Heart Failure outcomes were included in the base model training but were not available in the enhanced dataset used for the large model. This was due to data processing constraints during the transition to the enhanced feature set with 10-quantile encoding. As a result, direct comparison is only possible for Death, MI, and Stroke outcomes.
            </div>
            
            <h3>Model Architectures</h3>
            <p>We developed two model variants to investigate scale effects:</p>
            
            <div class="metric-grid">
                <div class="metric-item">
                    <div class="metric-value">27M</div>
                    <div class="metric-label">Base Model Parameters</div>
                    <p style="margin-top: 10px; font-size: 0.85em; color: #666;">
                        6 layers, 8 heads<br>
                        512 embedding dim<br>
                        6,153 vocabulary
                    </p>
                </div>
                <div class="metric-item">
                    <div class="metric-value">202M</div>
                    <div class="metric-label">Large Model Parameters</div>
                    <p style="margin-top: 10px; font-size: 0.85em; color: #666;">
                        12 layers, 16 heads<br>
                        1,024 embedding dim<br>
                        21,899 vocabulary
                    </p>
                </div>
            </div>
            
            <h3>Key Innovations</h3>
            
            <h4>1. Random Prediction Point Framework</h4>
            <p>Traditional approaches fix prediction points relative to specific clinical events. We introduce random prediction points throughout patient timelines, increasing training efficiency by 3.7× while better representing real-world deployment scenarios.</p>
            
            <div class="code-block">
# Traditional approach (limited training samples)
prediction_point = first_clinical_event + 1_year

# Our approach (more diverse training)
prediction_point = random_sample(patient_timeline)
baseline_window = [max(prediction_point - 5_years, start), prediction_point]
outcome_window = [prediction_point, prediction_point + 1_year]
            </div>
            
            <h4>2. Quantile-Based Feature Encoding</h4>
            <p>We transform continuous laboratory values into population-referenced quantiles, capturing non-linear relationships while maintaining interpretability:</p>
            
            <div class="figure">
                <svg width="600" height="300" viewBox="0 0 600 300">
                    <rect width="600" height="300" fill="#f8f9fa"/>
                    <text x="300" y="30" text-anchor="middle" font-size="16" font-weight="600">Quantile Encoding Example: Serum Creatinine</text>
                    
                    <!-- Distribution curve -->
                    <path d="M 50 250 Q 150 150, 300 200 T 550 250" fill="none" stroke="#0066cc" stroke-width="2"/>
                    
                    <!-- Quantile divisions -->
                    <line x1="130" y1="50" x2="130" y2="250" stroke="#666" stroke-dasharray="5,5"/>
                    <line x1="230" y1="50" x2="230" y2="250" stroke="#666" stroke-dasharray="5,5"/>
                    <line x1="300" y1="50" x2="300" y2="250" stroke="#666" stroke-dasharray="5,5"/>
                    <line x1="370" y1="50" x2="370" y2="250" stroke="#666" stroke-dasharray="5,5"/>
                    <line x1="470" y1="50" x2="470" y2="250" stroke="#666" stroke-dasharray="5,5"/>
                    
                    <!-- Labels -->
                    <text x="90" y="270" text-anchor="middle" font-size="12">Q1</text>
                    <text x="180" y="270" text-anchor="middle" font-size="12">Q2</text>
                    <text x="265" y="270" text-anchor="middle" font-size="12">Q3</text>
                    <text x="335" y="270" text-anchor="middle" font-size="12">Q4</text>
                    <text x="420" y="270" text-anchor="middle" font-size="12">Q5</text>
                    <text x="520" y="270" text-anchor="middle" font-size="12">Q6+</text>
                    
                    <!-- Value ranges -->
                    <text x="90" y="290" text-anchor="middle" font-size="10" fill="#666">0.5-0.8</text>
                    <text x="180" y="290" text-anchor="middle" font-size="10" fill="#666">0.8-1.0</text>
                    <text x="265" y="290" text-anchor="middle" font-size="10" fill="#666">1.0-1.2</text>
                    <text x="335" y="290" text-anchor="middle" font-size="10" fill="#666">1.2-1.6</text>
                    <text x="420" y="290" text-anchor="middle" font-size="10" fill="#666">1.6-2.5</text>
                    <text x="520" y="290" text-anchor="middle" font-size="10" fill="#666">&gt;2.5</text>
                </svg>
                <p class="figure-caption"><strong>Figure 1:</strong> Population-based quantile encoding transforms continuous laboratory values into discrete tokens while preserving clinical meaning. Values are divided into equal-frequency bins based on the entire population distribution.</p>
            </div>
            
            <h4>3. Multi-Scale Temporal Encoding</h4>
            <p>Medical events have complex temporal relationships. Our approach captures multiple time scales simultaneously:</p>
            
            <ul style="margin: 20px 0; padding-left: 30px;">
                <li><strong>Absolute time:</strong> Days since reference date (captures seasonal patterns)</li>
                <li><strong>Relative time:</strong> Days between consecutive events (captures episode density)</li>
                <li><strong>Patient age:</strong> Age at each event (captures life stage effects)</li>
                <li><strong>Temporal patterns:</strong> Hour of day, day of week (captures healthcare access patterns)</li>
            </ul>
        </section>
        
        <section id="experiments">
            <h2>Experimental Setup</h2>
            
            <h3>Training Pipeline</h3>
            <p>Both models followed a two-stage training approach:</p>
            
            <div class="metric-card">
                <h4>Stage 1: Self-Supervised Pretraining</h4>
                <p>Models were pretrained on unlabeled medical sequences using masked language modeling (MLM) and sequence order prediction (SOP) objectives. This stage allows models to learn general medical patterns without outcome labels.</p>
                <ul style="margin: 15px 0; padding-left: 25px;">
                    <li>Base model: 50 epochs on 27M parameters</li>
                    <li>Large model: 88 epochs on 202M parameters (H100 GPU)</li>
                    <li>Effective batch size: 128 (with gradient accumulation)</li>
                    <li>Learning rate: 1e-4 with cosine scheduling</li>
                </ul>
            </div>
            
            <div class="metric-card">
                <h4>Stage 2: Supervised Fine-tuning</h4>
                <p>Pretrained models were fine-tuned for multi-label outcome prediction with careful optimization for class imbalance.</p>
                <ul style="margin: 15px 0; padding-left: 25px;">
                    <li>10 epochs with early stopping</li>
                    <li>Class-weighted loss functions</li>
                    <li>AUC-based model selection (not loss-based)</li>
                    <li>Comprehensive regularization (dropout 0.3)</li>
                </ul>
            </div>
            
            <h3>Evaluation Methodology</h3>
            <p>We employed rigorous evaluation practices to ensure reliable results:</p>
            
            <ol style="margin: 20px 0; padding-left: 30px; line-height: 1.8;">
                <li><strong>Random train/validation splits:</strong> 80/20 split with patient-level stratification</li>
                <li><strong>Multiple metrics:</strong> AUROC (discrimination), AUPRC (positive class performance), calibration</li>
                <li><strong>Statistical significance:</strong> Bootstrapped confidence intervals for all metrics</li>
                <li><strong>Computational efficiency:</strong> Training time, memory usage, inference speed</li>
            </ol>
            
            <div class="highlight-box">
                <h4>Important Note on Reproducibility</h4>
                <p>All code, configurations, and model architectures are available in our repository. The random prediction point framework is implemented to ensure reproducible training despite the stochastic sampling process.</p>
            </div>
        </section>
        
        <section id="results">
            <h2>Results</h2>
            
            <h3>Primary Findings</h3>
            <p>Our experiments reveal a nuanced relationship between model scale and performance:</p>
            
            <div class="figure">
                <div class="comparison-chart">
                    <div style="display: flex; justify-content: space-around; align-items: flex-end; height: 320px;">
                        <div class="bar" style="width: 15%;">
                            <div class="bar-inner" style="height: 240px; background: #4CAF50;"></div>
                            <div class="bar-value">0.801</div>
                            <div class="bar-label">Death<br>Base</div>
                        </div>
                        <div class="bar" style="width: 15%;">
                            <div class="bar-inner" style="height: 280px; background: #8BC34A;"></div>
                            <div class="bar-value">0.932</div>
                            <div class="bar-label">Death<br>Large</div>
                        </div>
                        <div class="bar" style="width: 15%;">
                            <div class="bar-inner" style="height: 247px; background: #FF9800;"></div>
                            <div class="bar-value">0.823</div>
                            <div class="bar-label">MI<br>Base</div>
                        </div>
                        <div class="bar" style="width: 15%;">
                            <div class="bar-inner" style="height: 221px; background: #FF5722;"></div>
                            <div class="bar-value">0.738</div>
                            <div class="bar-label">MI<br>Large</div>
                        </div>
                        <div class="bar" style="width: 15%;">
                            <div class="bar-inner" style="height: 251px; background: #2196F3;"></div>
                            <div class="bar-value">0.835</div>
                            <div class="bar-label">Stroke<br>Base</div>
                        </div>
                        <div class="bar" style="width: 15%;">
                            <div class="bar-inner" style="height: 223px; background: #03A9F4;"></div>
                            <div class="bar-value">0.743</div>
                            <div class="bar-label">Stroke<br>Large</div>
                        </div>
                    </div>
                </div>
                <p class="figure-caption"><strong>Figure 2:</strong> AUROC performance comparison between base (27M) and large (202M) models. Green bars indicate improved performance with scale, while orange/blue bars show degraded performance. The large model excels at mortality prediction but underperforms on rare events.</p>
            </div>
            
            <h3>Detailed Performance Metrics</h3>
            
            <table>
                <thead>
                    <tr>
                        <th>Metric</th>
                        <th>Base Model (27M)</th>
                        <th>Large Model (202M)</th>
                        <th>Difference</th>
                        <th>Interpretation</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Mortality AUROC</strong></td>
                        <td>0.801</td>
                        <td>0.932</td>
                        <td style="color: #4CAF50;">+0.131</td>
                        <td>Exceptional improvement</td>
                    </tr>
                    <tr>
                        <td><strong>Mortality AUPRC</strong></td>
                        <td>0.023</td>
                        <td>0.744</td>
                        <td style="color: #4CAF50;">+0.721</td>
                        <td>32× better positive class detection</td>
                    </tr>
                    <tr>
                        <td><strong>MI AUROC</strong></td>
                        <td>0.823</td>
                        <td>0.755</td>
                        <td style="color: #F44336;">-0.068</td>
                        <td>Moderate degradation</td>
                    </tr>
                    <tr>
                        <td><strong>Stroke AUROC</strong></td>
                        <td>0.835</td>
                        <td>0.757</td>
                        <td style="color: #F44336;">-0.078</td>
                        <td>Significant degradation</td>
                    </tr>
                    <tr>
                        <td><strong>Macro-averaged AUROC</strong></td>
                        <td>0.816</td>
                        <td>0.820</td>
                        <td style="color: #4CAF50;">+0.004</td>
                        <td>Minimal overall change</td>
                    </tr>
                </tbody>
            </table>
            
            <h3>The Prevalence-Performance Relationship</h3>
            
            <p>A key finding is the strong relationship between outcome prevalence and the benefit of model scaling:</p>
            
            <div class="figure">
                <svg width="700" height="400" viewBox="0 0 700 400">
                    <rect width="700" height="400" fill="#f8f9fa"/>
                    
                    <!-- Title -->
                    <text x="350" y="30" text-anchor="middle" font-size="16" font-weight="600">Performance Improvement vs Outcome Prevalence</text>
                    
                    <!-- Axes -->
                    <line x1="80" y1="350" x2="650" y2="350" stroke="#333" stroke-width="2"/>
                    <line x1="80" y1="350" x2="80" y2="50" stroke="#333" stroke-width="2"/>
                    
                    <!-- X-axis labels -->
                    <text x="365" y="390" text-anchor="middle" font-size="14">Outcome Prevalence (%)</text>
                    <text x="80" y="370" text-anchor="middle" font-size="12">0</text>
                    <text x="200" y="370" text-anchor="middle" font-size="12">0.5</text>
                    <text x="320" y="370" text-anchor="middle" font-size="12">1.0</text>
                    <text x="440" y="370" text-anchor="middle" font-size="12">1.5</text>
                    <text x="560" y="370" text-anchor="middle" font-size="12">2.0</text>
                    
                    <!-- Y-axis labels -->
                    <text x="30" y="200" text-anchor="middle" font-size="14" transform="rotate(-90, 30, 200)">AUROC Improvement</text>
                    <text x="65" y="355" text-anchor="end" font-size="12">-0.10</text>
                    <text x="65" y="275" text-anchor="end" font-size="12">0.00</text>
                    <text x="65" y="195" text-anchor="end" font-size="12">0.10</text>
                    <text x="65" y="115" text-anchor="end" font-size="12">0.20</text>
                    
                    <!-- Zero line -->
                    <line x1="80" y1="270" x2="650" y2="270" stroke="#666" stroke-dasharray="5,5"/>
                    
                    <!-- Data points -->
                    <circle cx="156" cy="325" r="8" fill="#FF5722"/> <!-- MI: 0.34%, -0.068 -->
                    <circle cx="150" cy="335" r="8" fill="#03A9F4"/> <!-- Stroke: 0.32%, -0.078 -->
                    <circle cx="397" cy="140" r="8" fill="#4CAF50"/> <!-- Death: 0.85%, +0.131 -->
                    <!-- Labels for points -->
                    <text x="156" y="315" text-anchor="middle" font-size="11" fill="#333">MI</text>
                    <text x="150" y="355" text-anchor="middle" font-size="11" fill="#333">Stroke</text>
                    <text x="397" y="130" text-anchor="middle" font-size="11" fill="#333">Death</text>
                    
                    <!-- Trend line -->
                    <line x1="120" y1="340" x2="620" y2="160" stroke="#666" stroke-width="2" stroke-dasharray="10,5" opacity="0.5"/>
                    <text x="500" y="120" font-size="12" fill="#666">Trend: Higher prevalence → Better scaling</text>
                </svg>
                <p class="figure-caption"><strong>Figure 3:</strong> Relationship between outcome prevalence and performance improvement from model scaling. Outcomes with higher prevalence (mortality, heart failure) benefit from increased model capacity, while rare events (MI, stroke) show performance degradation.</p>
            </div>
            
            <div class="insight">
                <strong>Key Insight:</strong> The benefit of model scaling appears to be strongly correlated with outcome prevalence. This suggests that larger models require proportionally more positive examples to effectively learn discriminative patterns, while smaller models may be more efficient at learning from limited examples.
            </div>
            
            <h3>Computational Efficiency</h3>
            
            <div class="metric-grid">
                <div class="metric-item">
                    <div class="metric-value">7.5×</div>
                    <div class="metric-label">Parameter Increase</div>
                </div>
                <div class="metric-item">
                    <div class="metric-value">3.6×</div>
                    <div class="metric-label">Training Time Increase</div>
                </div>
                <div class="metric-item">
                    <div class="metric-value">3×</div>
                    <div class="metric-label">Memory Usage Increase</div>
                </div>
                <div class="metric-item">
                    <div class="metric-value">0.5%</div>
                    <div class="metric-label">Overall Performance Gain</div>
                </div>
            </div>
        </section>
        
        <section id="insights">
            <h2>Key Insights and Implications</h2>
            
            <h3>1. Task-Specific Scaling Benefits</h3>
            <p>Our results challenge the prevailing assumption that larger models universally outperform smaller ones. The dramatic improvement in mortality prediction (+16.4% relative AUROC improvement) demonstrates that scale can provide substantial benefits for certain tasks. However, the degradation in MI and stroke prediction suggests that this relationship is not universal.</p>
            
            <h3>2. The Role of Data Characteristics</h3>
            <p>Several factors appear to influence whether increased model capacity helps or hinders performance:</p>
            
            <div class="metric-card">
                <h4>Factors Favoring Large Models:</h4>
                <ul style="margin: 10px 0; padding-left: 25px;">
                    <li><strong>Higher prevalence:</strong> More training examples available</li>
                    <li><strong>Complex patterns:</strong> Death involves multiple organ systems and pathways</li>
                    <li><strong>Diverse features:</strong> Benefits from expanded vocabulary (21,899 vs 6,153 tokens)</li>
                    <li><strong>Long-term dependencies:</strong> Mortality prediction may involve subtle long-range patterns</li>
                </ul>
            </div>
            
            <div class="metric-card">
                <h4>Factors Favoring Smaller Models:</h4>
                <ul style="margin: 10px 0; padding-left: 25px;">
                    <li><strong>Rare events:</strong> Limited positive examples (0.3-0.4% prevalence)</li>
                    <li><strong>Specific markers:</strong> MI and stroke have well-defined clinical indicators</li>
                    <li><strong>Risk of overfitting:</strong> Large capacity with few examples</li>
                    <li><strong>Feature efficiency:</strong> Focused feature set may reduce noise</li>
                </ul>
            </div>
            
            <h3>3. Implications for Medical AI Development</h3>
            
            <p>These findings have important implications for the development and deployment of medical AI systems:</p>
            
            <ol style="margin: 20px 0; padding-left: 30px; line-height: 1.8;">
                <li><strong>No one-size-fits-all:</strong> Model architecture should be tailored to specific clinical tasks</li>
                <li><strong>Resource allocation:</strong> Computational resources may be better spent on data collection than model scaling for rare events</li>
                <li><strong>Ensemble opportunities:</strong> Combining models of different scales could leverage their complementary strengths</li>
                <li><strong>Deployment flexibility:</strong> Smaller models remain viable for many clinical applications</li>
            </ol>
            
            <h3>4. Methodological Contributions</h3>
            
            <p>Beyond the scaling insights, this work makes several methodological contributions:</p>
            
            <div class="highlight-box">
                <h4>Random Prediction Points</h4>
                <p>By sampling prediction points throughout patient timelines rather than fixing them relative to specific events, we increased training efficiency by 3.7× while creating a more realistic evaluation scenario. This approach could be broadly applicable to temporal medical prediction tasks.</p>
            </div>
            
            <div class="highlight-box">
                <h4>Comprehensive Optimization</h4>
                <p>Our optimization pipeline, including class weighting, AUC-based model selection, and proper regularization, improved performance by 76% over naive implementations. This highlights the importance of careful engineering in medical AI applications.</p>
            </div>
        </section>
        
        <section id="future">
            <h2>Future Directions</h2>
            
            <p>This investigation opens several avenues for future research:</p>
            
            <h3>1. Domain-Specific Adaptations</h3>
            <p>The framework we've developed could be adapted to other medical domains where temporal sequences play a crucial role:</p>
            <ul style="margin: 15px 0; padding-left: 30px;">
                <li>Oncology: Predicting treatment response and disease progression</li>
                <li>Mental health: Identifying risk factors for psychiatric events</li>
                <li>Pediatrics: Developmental milestone prediction</li>
                <li>Emergency medicine: Triage and deterioration prediction</li>
            </ul>
            
            <h3>2. Architectural Innovations</h3>
            <p>Several architectural modifications could address the limitations we observed:</p>
            <ul style="margin: 15px 0; padding-left: 30px;">
                <li><strong>Adaptive capacity:</strong> Models that dynamically adjust capacity based on task complexity</li>
                <li><strong>Hierarchical attention:</strong> Capturing both local clinical episodes and long-term patterns</li>
                <li><strong>Uncertainty quantification:</strong> Particularly important for rare event prediction</li>
                <li><strong>Interpretability mechanisms:</strong> Understanding which patterns drive predictions</li>
            </ul>
            
            <h3>3. Data Efficiency Techniques</h3>
            <p>For rare events where large models underperform, several techniques could improve data efficiency:</p>
            <ul style="margin: 15px 0; padding-left: 30px;">
                <li>Synthetic data generation using generative models</li>
                <li>Transfer learning from related but more common conditions</li>
                <li>Active learning to prioritize informative examples</li>
                <li>Multi-task learning to leverage shared patterns</li>
            </ul>
            
            <h3>4. Real-World Deployment Studies</h3>
            <p>Moving beyond retrospective analysis to prospective validation:</p>
            <ul style="margin: 15px 0; padding-left: 30px;">
                <li>Clinical integration pilots</li>
                <li>Multi-site validation studies</li>
                <li>Health economic impact assessments</li>
                <li>Fairness and bias evaluation across populations</li>
            </ul>
            
            <div class="insight">
                <strong>Call to Action:</strong> This work demonstrates both the promise and complexity of applying transformer architectures to medical sequences. We invite the research community to build upon these findings, particularly in exploring task-specific architectures and data-efficient learning techniques for rare clinical events.
            </div>
        </section>
    </main>
    
    <footer>
        <div class="container">
            <p>ASCEND Research Project | June 2025</p>
            <p>This research demonstrates the viability of transformer-based approaches for medical sequence modeling while revealing important nuances in the relationship between model scale and task performance.</p>
        </div>
    </footer>
    
    <script>
        // Simple smooth scrolling for navigation
        document.querySelectorAll('nav a').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const section = document.querySelector(this.getAttribute('href'));
                if (section) {
                    section.scrollIntoView({ behavior: 'smooth' });
                }
                
                // Update active state
                document.querySelectorAll('nav a').forEach(a => a.classList.remove('active'));
                this.classList.add('active');
            });
        });
        
        // Update active nav item on scroll
        window.addEventListener('scroll', () => {
            const sections = document.querySelectorAll('section');
            const navLinks = document.querySelectorAll('nav a');
            
            let current = '';
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                const sectionHeight = section.clientHeight;
                if (scrollY >= sectionTop - 200) {
                    current = section.getAttribute('id');
                }
            });
            
            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === `#${current}`) {
                    link.classList.add('active');
                }
            });
        });
    </script>
</body>
</html>