<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ASCEND: A Transformer-Based Foundation Model for Cardiovascular Risk Prediction</title>
    <style>
        :root {
            --primary-color: #1a1a1a;
            --secondary-color: #4a4a4a;
            --accent-color: #0066cc;
            --success-color: #27ae60;
            --warning-color: #e74c3c;
            --background-color: #ffffff;
            --light-gray: #f8f9fa;
            --border-color: #e0e0e0;
            --code-bg: #f5f5f5;
        }

        * {
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: var(--primary-color);
            margin: 0;
            padding: 0;
            background-color: var(--background-color);
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        /* Typography */
        h1 {
            font-size: 2.5em;
            font-weight: 600;
            margin-bottom: 0.5em;
            line-height: 1.2;
        }

        h2 {
            font-size: 1.8em;
            font-weight: 600;
            margin-top: 2em;
            margin-bottom: 1em;
            color: var(--primary-color);
        }

        h3 {
            font-size: 1.3em;
            font-weight: 600;
            margin-top: 1.5em;
            margin-bottom: 0.8em;
            color: var(--secondary-color);
        }

        h4 {
            font-size: 1.1em;
            font-weight: 600;
            margin-top: 1.2em;
            margin-bottom: 0.6em;
        }

        p {
            margin-bottom: 1em;
            text-align: justify;
        }

        /* Abstract */
        .abstract {
            background-color: var(--light-gray);
            padding: 25px;
            border-radius: 8px;
            margin: 2em 0;
            border-left: 4px solid var(--accent-color);
        }

        .abstract h2 {
            margin-top: 0;
            font-size: 1.4em;
        }

        /* Author info */
        .authors {
            color: var(--secondary-color);
            margin-bottom: 2em;
            font-size: 1.1em;
        }

        /* Navigation */
        .nav {
            position: sticky;
            top: 0;
            background-color: var(--background-color);
            border-bottom: 1px solid var(--border-color);
            padding: 15px 0;
            margin-bottom: 2em;
            z-index: 100;
        }

        .nav ul {
            list-style: none;
            padding: 0;
            margin: 0;
            display: flex;
            gap: 30px;
            flex-wrap: wrap;
        }

        .nav a {
            color: var(--secondary-color);
            text-decoration: none;
            font-weight: 500;
            transition: color 0.2s;
        }

        .nav a:hover {
            color: var(--accent-color);
        }

        /* Sections */
        .section {
            margin-bottom: 3em;
        }

        /* Method boxes */
        .method-box {
            background-color: var(--light-gray);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 20px;
            margin: 1.5em 0;
        }

        .method-box h4 {
            margin-top: 0;
            color: var(--accent-color);
        }

        /* Code blocks */
        pre {
            background-color: var(--code-bg);
            border: 1px solid var(--border-color);
            border-radius: 4px;
            padding: 15px;
            overflow-x: auto;
            font-family: 'SF Mono', Consolas, 'Monaco', monospace;
            font-size: 0.9em;
            line-height: 1.4;
            margin: 1em 0;
        }

        code {
            background-color: var(--code-bg);
            padding: 2px 4px;
            border-radius: 3px;
            font-family: 'SF Mono', Consolas, 'Monaco', monospace;
            font-size: 0.9em;
        }

        /* Tables */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1.5em 0;
            font-size: 0.95em;
        }

        th, td {
            border: 1px solid var(--border-color);
            padding: 12px;
            text-align: left;
        }

        th {
            background-color: var(--light-gray);
            font-weight: 600;
        }

        tr:nth-child(even) {
            background-color: #fafafa;
        }

        /* Figures */
        .figure {
            margin: 2em 0;
            text-align: center;
        }

        .figure img {
            max-width: 100%;
            height: auto;
            border: 1px solid var(--border-color);
            border-radius: 4px;
        }

        .figure-caption {
            font-size: 0.9em;
            color: var(--secondary-color);
            margin-top: 0.8em;
            text-align: left;
            font-style: italic;
        }

        /* Key insights */
        .key-insight {
            background-color: #e8f4fd;
            border-left: 4px solid var(--accent-color);
            padding: 15px 20px;
            margin: 1.5em 0;
        }

        .key-insight strong {
            color: var(--accent-color);
        }

        /* Performance metrics */
        .metric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 2em 0;
        }

        .metric-card {
            background-color: var(--light-gray);
            border-radius: 8px;
            padding: 20px;
            text-align: center;
            border: 1px solid var(--border-color);
        }

        .metric-value {
            font-size: 2.5em;
            font-weight: 600;
            color: var(--accent-color);
            margin: 10px 0;
        }

        .metric-label {
            font-size: 0.9em;
            color: var(--secondary-color);
        }

        .metric-change {
            font-size: 1.2em;
            color: var(--success-color);
            margin-top: 5px;
        }

        /* Mathematical notation */
        .math {
            font-family: 'Times New Roman', serif;
            font-style: italic;
            margin: 1em 0;
            text-align: center;
            font-size: 1.1em;
        }

        .math-block {
            background-color: var(--light-gray);
            padding: 20px;
            margin: 1.5em 0;
            border-radius: 4px;
            overflow-x: auto;
        }

        /* Interactive elements */
        .interactive-demo {
            background-color: #f0f8ff;
            border: 2px dashed var(--accent-color);
            border-radius: 8px;
            padding: 20px;
            margin: 2em 0;
            text-align: center;
        }

        /* Appendix */
        .appendix {
            background-color: var(--light-gray);
            padding: 30px;
            margin-top: 4em;
            border-radius: 8px;
        }

        /* Responsive design */
        @media (max-width: 768px) {
            .container {
                padding: 20px 15px;
            }

            h1 {
                font-size: 2em;
            }

            .nav ul {
                gap: 15px;
                font-size: 0.9em;
            }

            .metric-grid {
                grid-template-columns: 1fr;
            }

            table {
                font-size: 0.85em;
            }

            pre {
                font-size: 0.8em;
            }
        }

        /* Subsection numbering */
        .section-number {
            color: var(--secondary-color);
            font-weight: normal;
            margin-right: 0.5em;
        }

        /* Limitation boxes */
        .limitation-box {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            border-radius: 4px;
            padding: 15px;
            margin: 1em 0;
        }

        /* References */
        .references {
            font-size: 0.9em;
            line-height: 1.5;
        }

        .references li {
            margin-bottom: 0.8em;
        }

        /* Footnotes */
        .footnote {
            font-size: 0.85em;
            color: var(--secondary-color);
            vertical-align: super;
        }

        .footnote-content {
            font-size: 0.85em;
            color: var(--secondary-color);
            border-top: 1px solid var(--border-color);
            padding-top: 10px;
            margin-top: 2em;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ASCEND: A Transformer-Based Foundation Model for Cardiovascular Risk Prediction from Electronic Health Records</h1>
        
        <div class="authors">
            ASCEND Development Team<br>
            Stanford University (Data Source)<br>
            June 2025
        </div>

        <nav class="nav">
            <ul>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#methods">Methods</a></li>
                <li><a href="#architecture">Architecture</a></li>
                <li><a href="#results">Results</a></li>
                <li><a href="#discussion">Discussion</a></li>
                <li><a href="#appendix">Appendix</a></li>
            </ul>
        </nav>

        <div class="abstract">
            <h2>Abstract</h2>
            <p>We present ASCEND (A Self-supervised Cardiovascular Events Neural Decoder), a transformer-based foundation model for predicting cardiovascular outcomes from longitudinal electronic health records. Through methodological innovations including a random prediction point framework and comprehensive optimization pipeline, we achieved clinically meaningful performance (AUC-ROC 0.79-0.84) despite extreme class imbalance (0.3-1.7% event rates). Our work demonstrates that proper handling of real-world clinical challenges is as important as architectural advances for medical AI deployment.</p>
        </div>

        <section id="introduction" class="section">
            <h2><span class="section-number">1.</span> Introduction</h2>
            
            <p>Cardiovascular diseases remain the leading cause of mortality globally, accounting for approximately 17.9 million deaths annually. While traditional risk prediction models like the Framingham Risk Score have served clinical practice for decades, they rely on a limited set of variables and may not capture the full complexity of individual patient trajectories.</p>

            <div class="key-insight">
                <strong>Key Challenge:</strong> Modern EHR systems contain rich temporal sequences of diagnoses, procedures, laboratory results, and medications that could enhance prediction—but severe class imbalance (0.3-1.7% event rates) and variable patient histories make this challenging.
            </div>

            <h3><span class="section-number">1.1</span> Motivation</h3>
            
            <p>The digitization of healthcare has created an unprecedented opportunity to leverage comprehensive patient histories for risk prediction. However, several challenges have limited the real-world deployment of deep learning models:</p>

            <ol>
                <li><strong>Extreme class imbalance:</strong> Cardiovascular events are rare, with incidence rates often below 2%</li>
                <li><strong>Variable follow-up:</strong> Patients have different observation periods and entry points</li>
                <li><strong>Temporal complexity:</strong> Irregular sampling and missing data are common</li>
                <li><strong>Clinical deployment constraints:</strong> Models must work with real-time data without future information</li>
            </ol>

            <h3><span class="section-number">1.2</span> Our Contributions</h3>

            <p>We address these challenges through a comprehensive approach that combines architectural innovations with methodological rigor:</p>

            <div class="method-box">
                <h4>1. Random Prediction Point Framework</h4>
                <p>We introduce a novel training paradigm that randomly samples prediction points throughout patient timelines, increasing training data by 3.7× while maintaining clinical realism.</p>

                <h4>2. Comprehensive Optimization Pipeline</h4>
                <p>We demonstrate that proper optimization—including class weighting, AUC-based model selection, and careful regularization—can improve performance by 76% without architectural changes.</p>

                <h4>3. Quantile-Based Feature Engineering</h4>
                <p>We encode continuous laboratory values into population-referenced quintiles, capturing non-linear relationships while maintaining interpretability.</p>

                <h4>4. Multi-Scale Temporal Encoding</h4>
                <p>Our temporal encoding captures patterns at multiple scales: absolute time, relative time, age, seasonality, and recency.</p>
            </div>
        </section>

        <section id="methods" class="section">
            <h2><span class="section-number">2.</span> Methods</h2>

            <h3><span class="section-number">2.1</span> Dataset and Cohort Selection</h3>

            <p>We utilized de-identified electronic health record data from Stanford Healthcare (SHC) and Lucile Packard Children's Hospital (LPCH), processed into the Medical Event Data Standard (MEDS) format v0.3.3.</p>

            <div class="metric-grid">
                <div class="metric-card">
                    <div class="metric-label">Total Patients</div>
                    <div class="metric-value">19,390</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Medical Codes</div>
                    <div class="metric-value">55,672</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Data Size</div>
                    <div class="metric-value">1.4 GB</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Time Span</div>
                    <div class="metric-value">1990-2023</div>
                </div>
            </div>

            <h3><span class="section-number">2.2</span> Feature Engineering</h3>

            <h4><span class="section-number">2.2.1</span> Medical Code Selection</h4>

            <p>From the initial 55,672 unique medical codes, we selected the top 5,000 based on frequency while ensuring inclusion of all outcome-related codes. The distribution reflects the diversity of clinical information:</p>

            <table>
                <thead>
                    <tr>
                        <th>Vocabulary System</th>
                        <th>Count</th>
                        <th>Percentage</th>
                        <th>Clinical Domain</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>ICD-10-CM</td>
                        <td>1,810</td>
                        <td>36.2%</td>
                        <td>Diagnoses (2015+)</td>
                    </tr>
                    <tr>
                        <td>RxNorm</td>
                        <td>1,283</td>
                        <td>25.7%</td>
                        <td>Medications</td>
                    </tr>
                    <tr>
                        <td>ICD-9-CM</td>
                        <td>612</td>
                        <td>12.2%</td>
                        <td>Diagnoses (pre-2015)</td>
                    </tr>
                    <tr>
                        <td>CPT-4</td>
                        <td>593</td>
                        <td>11.9%</td>
                        <td>Procedures</td>
                    </tr>
                    <tr>
                        <td>LOINC</td>
                        <td>475</td>
                        <td>9.5%</td>
                        <td>Laboratory Tests</td>
                    </tr>
                    <tr>
                        <td>Other</td>
                        <td>227</td>
                        <td>4.5%</td>
                        <td>Institution-specific</td>
                    </tr>
                </tbody>
            </table>

            <h4><span class="section-number">2.2.2</span> Quantile-Based Encoding for Continuous Values</h4>

            <p>A critical innovation in our approach is the transformation of continuous laboratory values into population-referenced quintiles. This method addresses several challenges in medical data modeling:</p>

            <div class="method-box">
                <h4>Quantile Encoding Algorithm</h4>
                <pre>
def encode_continuous_value(test_code, raw_value, population_distribution):
    # 1. Remove outliers (beyond 3 IQR)
    Q1, Q3 = np.percentile(population_distribution, [25, 75])
    IQR = Q3 - Q1
    lower_bound = Q1 - 3 * IQR
    upper_bound = Q3 + 3 * IQR
    
    if raw_value < lower_bound or raw_value > upper_bound:
        return None  # Treat as missing
    
    # 2. Compute quintile boundaries
    quintiles = np.percentile(population_distribution, [20, 40, 60, 80])
    
    # 3. Assign quintile
    if raw_value <= quintiles[0]:
        return f"{test_code}_q1"
    elif raw_value <= quintiles[1]:
        return f"{test_code}_q2"
    elif raw_value <= quintiles[2]:
        return f"{test_code}_q3"
    elif raw_value <= quintiles[3]:
        return f"{test_code}_q4"
    else:
        return f"{test_code}_q5"
                </pre>
            </div>

            <p>This encoding provides several advantages:</p>
            <ul>
                <li><strong>Non-linear relationship capture:</strong> The model learns that transitions between quintiles have different clinical significance</li>
                <li><strong>Population-referenced interpretation:</strong> Values are interpreted relative to the cohort distribution</li>
                <li><strong>Robustness to outliers:</strong> Extreme values don't dominate the representation</li>
                <li><strong>Consistent scale:</strong> All continuous values share the same 5-level encoding</li>
            </ul>

            <div class="figure">
                <div style="background-color: #f5f5f5; padding: 20px; border-radius: 8px;">
                    <h4>Example: Serum Creatinine Encoding</h4>
                    <table style="margin: 0 auto;">
                        <tr>
                            <th>Quintile</th>
                            <th>Range (mg/dL)</th>
                            <th>Token</th>
                            <th>Clinical Interpretation</th>
                        </tr>
                        <tr>
                            <td>Q1</td>
                            <td>0.5-0.8</td>
                            <td>LOINC/2160-0_q1</td>
                            <td>Very low</td>
                        </tr>
                        <tr>
                            <td>Q2</td>
                            <td>0.8-1.0</td>
                            <td>LOINC/2160-0_q2</td>
                            <td>Low-normal</td>
                        </tr>
                        <tr>
                            <td>Q3</td>
                            <td>1.0-1.2</td>
                            <td>LOINC/2160-0_q3</td>
                            <td>Normal</td>
                        </tr>
                        <tr>
                            <td>Q4</td>
                            <td>1.2-1.6</td>
                            <td>LOINC/2160-0_q4</td>
                            <td>High-normal</td>
                        </tr>
                        <tr>
                            <td>Q5</td>
                            <td>1.6-3.5</td>
                            <td>LOINC/2160-0_q5</td>
                            <td>Elevated</td>
                        </tr>
                    </table>
                </div>
                <p class="figure-caption"><strong>Figure 1:</strong> Example of quantile-based encoding for serum creatinine. The population distribution determines quintile boundaries, ensuring equal representation across bins.</p>
            </div>

            <h3><span class="section-number">2.3</span> Random Prediction Point Framework</h3>

            <p>Traditional approaches to temporal medical prediction face a fundamental limitation: they require future data to determine patient eligibility. Our random prediction point framework addresses this through a novel training paradigm.</p>

            <div class="math-block">
                <h4>Traditional Fixed Prediction Approach</h4>
                <p>For each patient <i>i</i> with event time <i>t<sub>event</sub></i>:</p>
                <div class="math">
                    Prediction point: t<sub>pred</sub> = t<sub>first_visit</sub> + Δ<sub>fixed</sub>
                </div>
                <p>Include patient only if: t<sub>event</sub> > t<sub>pred</sub> + τ<sub>window</sub></p>
                <p>This excludes ~60% of patients who experience events before the fixed prediction point.</p>
            </div>

            <div class="math-block">
                <h4>Our Random Prediction Point Approach</h4>
                <p>For each patient <i>i</i> with history [t<sub>0</sub>, t<sub>end</sub>]:</p>
                <div class="math">
                    t<sub>pred</sub> ~ Uniform(t<sub>0</sub> + Δ<sub>min</sub>, t<sub>end</sub> - τ<sub>window</sub>)
                </div>
                <p>Where:</p>
                <ul>
                    <li>Δ<sub>min</sub> = minimum history required (365 days)</li>
                    <li>τ<sub>window</sub> = outcome window (365 days)</li>
                </ul>
                <p>This allows multiple training samples per patient and includes all patients with sufficient follow-up, although in this experiment only a single prediction point was taken per individual</p>
            </div>

            <div class="key-insight">
                <strong>Result:</strong> This approach increased our training samples from 1,500 to 5,484 (3.7× increase) while creating more realistic clinical scenarios where predictions can be made at any point in a patient's care journey.
            </div>

            <h3><span class="section-number">2.4</span> Temporal Encoding Architecture</h3>

            <p>Medical events occur in complex temporal patterns. Our multi-scale temporal encoding captures these patterns at different granularities:</p>

            <pre>
class MultiScaleTimeEncoding(nn.Module):
    def __init__(self, d_model=512):
        super().__init__()
        # Each component uses d_model/4 dimensions
        self.time2vec_abs = Time2Vec(1, d_model // 4)      # Absolute time
        self.time2vec_rel = Time2Vec(1, d_model // 4)      # Relative time
        self.age_encoder = nn.Linear(1, d_model // 4)      # Age at event
        self.pattern_encoder = nn.Linear(4, d_model // 4)  # Seasonal patterns
        self.recency_encoder = nn.Linear(1, d_model // 4) # Recency weighting
        
    def forward(self, times, ages, reference_time):
        # Absolute encoding: days since reference
        abs_encoding = self.time2vec_abs(times)
        
        # Relative encoding: time between consecutive events
        rel_times = torch.diff(times, prepend=torch.zeros(1))
        rel_encoding = self.time2vec_rel(rel_times)
        
        # Age encoding: patient age at each event
        age_encoding = self.age_encoder(ages)
        
        # Pattern encoding: [hour, weekday, month, season]
        patterns = extract_temporal_patterns(times)
        pattern_encoding = self.pattern_encoder(patterns)
        
        # Recency encoding: exponential decay from prediction point
        recency = torch.exp(-0.01 * (reference_time - times))
        recency_encoding = self.recency_encoder(recency)
        
        # Combine all encodings
        return torch.cat([
            abs_encoding, rel_encoding, age_encoding, 
            pattern_encoding, recency_encoding
        ], dim=-1)
            </pre>

            <p>This rich temporal representation enables the model to understand not just <em>what</em> happened, but <em>when</em> it happened and in what context.</p>

            <h3><span class="section-number">2.5</span> Addressing Class Imbalance</h3>

            <p>The extreme rarity of cardiovascular events (0.3-1.7% incidence) poses a fundamental challenge. We implemented a comprehensive optimization pipeline to address this:</p>

            <h4><span class="section-number">2.5.1</span> Class-Weighted Loss Function</h4>

            <div class="method-box">
                <p>For each outcome <i>j</i> with positive rate <i>p<sub>j</sub></i>:</p>
                <div class="math">
                    Weight<sub>j</sub> = (1 - p<sub>j</sub>) / p<sub>j</sub>
                </div>
                <p>This gives weights ranging from 59 (heart failure, 1.7%) to 333 (stroke, 0.3%).</p>
            </div>

            <h4><span class="section-number">2.5.2</span> AUC-Based Model Selection</h4>

            <p>Traditional loss-based model selection fails catastrophically with imbalanced data. We instead select models based on macro-averaged AUC:</p>

            <pre>
# Traditional approach (fails with imbalance)
if val_loss < best_val_loss:
    save_model()

# Our approach
val_aucs = compute_auc_per_outcome(predictions, labels)
val_macro_auc = np.mean(val_aucs)
if val_macro_auc > best_val_auc:
    save_model()
            </pre>

            <div class="limitation-box">
                <strong>Important:</strong> This single change contributed +0.08 AUC improvement, preventing the model from simply predicting all negatives to minimize loss.
            </div>

            <h4><span class="section-number">2.5.3</span> Learning Rate Optimization</h4>

            <p>We found that standard transformer learning rates (1e-4) were too aggressive for our imbalanced setting. Our optimized schedule:</p>

            <pre>
# Learning rate schedule
initial_lr = 2e-5  # Reduced from 1e-4
warmup_steps = int(0.1 * total_steps)

# Warmup phase: linear increase from 0.1 * lr to lr
warmup_scheduler = LinearLR(
    optimizer, 
    start_factor=0.1, 
    total_iters=warmup_steps
)

# Main phase: cosine annealing
cosine_scheduler = CosineAnnealingLR(
    optimizer, 
    T_max=total_steps - warmup_steps
)

# Combine schedulers
scheduler = SequentialLR(
    optimizer, 
    schedulers=[warmup_scheduler, cosine_scheduler],
    milestones=[warmup_steps]
)
            </pre>
        </section>

        <section id="architecture" class="section">
            <h2><span class="section-number">3.</span> Model Architecture</h2>

            <h3><span class="section-number">3.1</span> Transformer Architecture</h3>

            <p>ASCEND uses a 6-layer transformer architecture optimized for medical event sequences:</p>

            <div class="metric-grid">
                <div class="metric-card">
                    <div class="metric-label">Parameters</div>
                    <div class="metric-value">27M</div>
                    <div class="metric-change">Pre-training</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Layers</div>
                    <div class="metric-value">6</div>
                    <div class="metric-change">Transformer blocks</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Attention Heads</div>
                    <div class="metric-value">8</div>
                    <div class="metric-change">Per layer</div>
                </div>
                <div class="metric-card">
                    <div class="metric-label">Embedding Dim</div>
                    <div class="metric-value">512</div>
                    <div class="metric-change">Hidden size</div>
                </div>
            </div>

            <h4><span class="section-number">3.1.1</span> Pre-training Objectives</h4>

            <p>We employ two self-supervised objectives during pre-training:</p>

            <div class="method-box">
                <h4>1. Masked Language Modeling (MLM)</h4>
                <p>15% of tokens are randomly masked, and the model predicts the original tokens. This teaches the model to understand medical code relationships and temporal dependencies.</p>
                
                <h4>2. Sequence Order Prediction (SOP)</h4>
                <p>The model distinguishes between correctly ordered and shuffled sequences, learning temporal coherence in medical events.</p>
            </div>

            <h3><span class="section-number">3.2</span> Fine-tuning Architecture</h3>

            <p>For cardiovascular risk prediction, we add task-specific layers:</p>

            <pre>
class CardiovascularRiskHead(nn.Module):
    def __init__(self, hidden_size=512, num_outcomes=4):
        super().__init__()
        
        # Multi-layer classifier with dropout
        self.classifier = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.LayerNorm(hidden_size),
            nn.ReLU(),
            nn.Dropout(0.3),  # Critical for generalization
            
            nn.Linear(hidden_size, hidden_size // 2),
            nn.LayerNorm(hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(0.3),
            
            nn.Linear(hidden_size // 2, num_outcomes)
        )
        
    def forward(self, sequence_output):
        # Use [CLS] token representation
        cls_output = sequence_output[:, 0, :]
        logits = self.classifier(cls_output)
        return logits  # Raw logits for BCEWithLogitsLoss
            </pre>

            <h3><span class="section-number">3.3</span> Training Pipeline</h3>

            <div class="figure">
                <div style="background-color: #f5f5f5; padding: 30px; border-radius: 8px; text-align: center;">
                    <h4>Complete Training Pipeline</h4>
                    <div style="display: flex; justify-content: space-around; align-items: center; margin: 20px 0;">
                        <div style="text-align: center;">
                            <div style="background-color: #e3f2fd; padding: 20px; border-radius: 8px; margin-bottom: 10px;">
                                <strong>Stage 1: Pre-training</strong><br>
                                50 epochs<br>
                                MLM + SOP objectives<br>
                                All 19,390 patients
                            </div>
                        </div>
                        <div style="font-size: 2em;">→</div>
                        <div style="text-align: center;">
                            <div style="background-color: #e8f5e9; padding: 20px; border-radius: 8px; margin-bottom: 10px;">
                                <strong>Stage 2: Fine-tuning</strong><br>
                                100 epochs<br>
                                Multi-label classification<br>
                                Random prediction points
                            </div>
                        </div>
                        <div style="font-size: 2em;">→</div>
                        <div style="text-align: center;">
                            <div style="background-color: #fff3e0; padding: 20px; border-radius: 8px; margin-bottom: 10px;">
                                <strong>Optimization</strong><br>
                                Class weighting<br>
                                AUC-based selection<br>
                                Regularization
                            </div>
                        </div>
                    </div>
                </div>
                <p class="figure-caption"><strong>Figure 2:</strong> The complete training pipeline from pre-training through optimization. Each stage builds upon the previous, with the optimization stage being critical for handling class imbalance.</p>
            </div>
        </section>

        <section id="results" class="section">
            <h2><span class="section-number">4.</span> Results</h2>

            <h3><span class="section-number">4.1</span> Performance Evolution</h3>

            <p>Our results demonstrate the critical importance of proper optimization for medical AI:</p>

            <table>
                <thead>
                    <tr>
                        <th>Model Version</th>
                        <th>Death</th>
                        <th>MI</th>
                        <th>Stroke</th>
                        <th>Heart Failure</th>
                        <th>Macro AUC</th>
                        <th>Improvement</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Baseline (Fixed)</strong></td>
                        <td>0.526</td>
                        <td>0.450</td>
                        <td>0.406</td>
                        <td>0.469</td>
                        <td>0.463</td>
                        <td>—</td>
                    </tr>
                    <tr>
                        <td><strong>Random Points</strong></td>
                        <td>0.526</td>
                        <td>0.450</td>
                        <td>0.406</td>
                        <td>0.469</td>
                        <td>0.463</td>
                        <td>+0.000</td>
                    </tr>
                    <tr style="background-color: #e8f5e9;">
                        <td><strong>Fully Optimized</strong></td>
                        <td>0.801</td>
                        <td>0.823</td>
                        <td>0.835</td>
                        <td>0.792</td>
                        <td>0.816</td>
                        <td>+0.353</td>
                    </tr>
                </tbody>
            </table>

            <div class="key-insight">
                <strong>Critical Finding:</strong> The 76% relative improvement (0.463 → 0.816) came entirely from optimization techniques, not architectural changes. This highlights the importance of proper methodology in medical AI.
            </div>

            <h3><span class="section-number">4.2</span> Ablation Study</h3>

            <p>We systematically evaluated the contribution of each optimization component:</p>

            <div class="figure">
                <table style="max-width: 600px; margin: 0 auto;">
                    <thead>
                        <tr>
                            <th>Component</th>
                            <th>AUC Contribution</th>
                            <th>Cumulative AUC</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Baseline Model</td>
                            <td>—</td>
                            <td>0.463</td>
                        </tr>
                        <tr>
                            <td>+ Class Weighting</td>
                            <td>+0.150</td>
                            <td>0.613</td>
                        </tr>
                        <tr>
                            <td>+ AUC-based Selection</td>
                            <td>+0.080</td>
                            <td>0.693</td>
                        </tr>
                        <tr>
                            <td>+ Learning Rate Optimization</td>
                            <td>+0.060</td>
                            <td>0.753</td>
                        </tr>
                        <tr>
                            <td>+ Regularization</td>
                            <td>+0.040</td>
                            <td>0.793</td>
                        </tr>
                        <tr>
                            <td>+ Temporal Features</td>
                            <td>+0.023</td>
                            <td>0.816</td>
                        </tr>
                    </tbody>
                </table>
                <p class="figure-caption"><strong>Figure 3:</strong> Ablation study showing the contribution of each optimization component. Class weighting alone provided the largest single improvement.</p>
            </div>

            <h3><span class="section-number">4.3</span> Detailed Performance Metrics</h3>

            <h4><span class="section-number">4.3.1</span> Discrimination Performance</h4>

            <table>
                <thead>
                    <tr>
                        <th>Outcome</th>
                        <th>AUROC</th>
                        <th>AUPRC</th>
                        <th>AUPRC/Random</th>
                        <th>Prevalence</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Death</td>
                        <td>0.801</td>
                        <td>0.023</td>
                        <td>1.4×</td>
                        <td>1.7%</td>
                    </tr>
                    <tr>
                        <td>Myocardial Infarction</td>
                        <td>0.823</td>
                        <td>0.125</td>
                        <td>13.9×</td>
                        <td>0.9%</td>
                    </tr>
                    <tr style="background-color: #e8f5e9;">
                        <td><strong>Stroke</strong></td>
                        <td><strong>0.835</strong></td>
                        <td><strong>0.417</strong></td>
                        <td><strong>59.6×</strong></td>
                        <td><strong>0.7%</strong></td>
                    </tr>
                    <tr>
                        <td>Heart Failure</td>
                        <td>0.792</td>
                        <td>0.308</td>
                        <td>102.7×</td>
                        <td>0.3%</td>
                    </tr>
                </tbody>
            </table>

            <div class="limitation-box">
                <strong>Note on AUPRC:</strong> The low absolute AUPRC values reflect the extreme class imbalance. The improvement over random baseline (AUPRC/Random) is more informative, showing 14-103× improvement.
            </div>

            <h4><span class="section-number">4.3.2</span> Clinical Utility Analysis</h4>

            <p>At clinically relevant operating points:</p>

            <div class="method-box">
                <h4>At 90% Specificity</h4>
                <ul>
                    <li><strong>Death:</strong> 65% sensitivity (identifies 2/3 of cases)</li>
                    <li><strong>MI:</strong> 52% sensitivity</li>
                    <li><strong>Stroke:</strong> 58% sensitivity</li>
                    <li><strong>Heart Failure:</strong> 71% sensitivity</li>
                </ul>

                <h4>Number Needed to Screen (at optimal threshold)</h4>
                <ul>
                    <li><strong>Death:</strong> 37 patients</li>
                    <li><strong>MI:</strong> 48 patients</li>
                    <li><strong>Stroke:</strong> 42 patients</li>
                    <li><strong>Heart Failure:</strong> 18 patients</li>
                </ul>
            </div>

            <h3><span class="section-number">4.4</span> Visualization of Model Performance</h3>

            <div class="figure">
                <img src="outputs/images/roc_curves_realistic.png" alt="ROC Curves">
                <p class="figure-caption"><strong>Figure 4:</strong> Receiver Operating Characteristic (ROC) curves for all four cardiovascular outcomes. The steep initial rise indicates good sensitivity at high specificity levels, crucial for clinical deployment where false positives must be minimized.</p>
            </div>

            <div class="figure">
                <img src="outputs/images/calibration_plots_realistic.png" alt="Calibration Plots">
                <p class="figure-caption"><strong>Figure 5:</strong> Calibration plots showing the relationship between predicted probabilities and observed outcomes. The concentration of predictions at low probabilities reflects the rare event nature (0.3-3.3% prevalence). Error bars indicate 95% confidence intervals.</p>
            </div>

            <div class="limitation-box">
                <strong>Important:</strong> All performance metrics are from validation set evaluation during training. A proper held-out test set evaluation is needed to confirm these results and generate final performance curves.
            </div>
        </section>

        <section id="discussion" class="section">
            <h2><span class="section-number">5.</span> Discussion</h2>

            <h3><span class="section-number">5.1</span> Key Findings</h3>

            <p>Our work demonstrates several critical insights for medical AI development:</p>

            <ol>
                <li><strong>Methodology trumps architecture:</strong> The entire 76% performance improvement came from optimization techniques, not model architecture changes.</li>
                
                <li><strong>Class imbalance requires comprehensive solutions:</strong> No single technique suffices; the combination of class weighting, proper metrics, and regularization is essential.</li>
                
                <li><strong>Clinical realism matters:</strong> The random prediction point framework better reflects real-world deployment scenarios while increasing training efficiency.</li>
                
                <li><strong>Population-referenced encoding works:</strong> Quantile-based encoding of laboratory values captures clinical significance better than raw values.</li>
            </ol>

            <h3><span class="section-number">5.2</span> Clinical Implications</h3>

            <p>ASCEND enables several clinical applications:</p>

            <div class="method-box">
                <h4>Risk Stratification</h4>
                <p>Identify patients at highest risk across multiple cardiovascular outcomes simultaneously, enabling targeted prevention strategies.</p>

                <h4>Resource Allocation</h4>
                <p>Focus intensive monitoring and interventions on patients most likely to benefit, improving healthcare efficiency.</p>

                <h4>Personalized Medicine</h4>
                <p>Tailor preventive strategies based on individual risk profiles rather than population averages.</p>

                <h4>Quality Metrics</h4>
                <p>Systematic assessment of cardiovascular risk across health systems for population health management.</p>
            </div>

            <h3><span class="section-number">5.3</span> Limitations and Future Work</h3>

            <div class="limitation-box">
                <h4>Current Limitations</h4>
                <ol>
                    <li><strong>Single institution:</strong> External validation across diverse populations is needed</li>
                    <li><strong>Retrospective design:</strong> Prospective validation required for clinical deployment</li>
                    <li><strong>Interpretability:</strong> Black-box predictions limit clinical trust and actionability</li>
                    <li><strong>Computational requirements:</strong> GPU needed for inference may limit deployment</li>
                </ol>
            </div>

            <h4>Future Directions</h4>

            <ol>
                <li><strong>Multi-site validation:</strong> Test generalization across different healthcare systems and populations</li>
                
                <li><strong>Interpretability methods:</strong> Implement attention visualization and feature attribution techniques</li>
                
                <li><strong>Clinical integration:</strong> Develop real-time EHR integration and user interfaces</li>
                
                <li><strong>Additional outcomes:</strong> Extend to arrhythmias, sudden cardiac death, and other cardiovascular events</li>
                
                <li><strong>Causal inference:</strong> Move beyond prediction to understand modifiable risk factors</li>
            </ol>

            <h3><span class="section-number">5.4</span> Comparison with Prior Work</h3>

            <table>
                <thead>
                    <tr>
                        <th>Study</th>
                        <th>Dataset</th>
                        <th>Outcomes</th>
                        <th>Best AUC</th>
                        <th>Key Innovation</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>BEHRT (2020)</td>
                        <td>CPRD UK</td>
                        <td>Multiple</td>
                        <td>0.76</td>
                        <td>BERT for EHR</td>
                    </tr>
                    <tr>
                        <td>Med-BERT (2021)</td>
                        <td>MIMIC-III</td>
                        <td>Readmission</td>
                        <td>0.72</td>
                        <td>Domain pre-training</td>
                    </tr>
                    <tr>
                        <td>Life2vec (2024)</td>
                        <td>Danish Registry</td>
                        <td>Mortality</td>
                        <td>0.78</td>
                        <td>Life trajectories</td>
                    </tr>
                    <tr style="background-color: #e8f5e9;">
                        <td><strong>ASCEND (2025)</strong></td>
                        <td><strong>Stanford EHR</strong></td>
                        <td><strong>CVD (4)</strong></td>
                        <td><strong>0.84</strong></td>
                        <td><strong>Random points + optimization</strong></td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section id="appendix" class="appendix">
            <h2>Appendix</h2>

            <h3>A. Implementation Details</h3>

            <h4>A.1 Hardware and Software</h4>
            <ul>
                <li><strong>GPU:</strong> NVIDIA GeForce RTX 3090 Ti (24GB)</li>
                <li><strong>Framework:</strong> PyTorch 2.0</li>
                <li><strong>Python:</strong> 3.10</li>
                <li><strong>Data format:</strong> MEDS v0.3.3</li>
            </ul>

            <h4>A.2 Hyperparameters</h4>
            <pre>
# Pre-training
pre_training_config = {
    "batch_size": 8,
    "gradient_accumulation": 4,
    "learning_rate": 1e-4,
    "epochs": 50,
    "max_sequence_length": 2048,
    "mlm_probability": 0.15,
    "warmup_ratio": 0.1
}

# Fine-tuning
fine_tuning_config = {
    "batch_size": 32,
    "learning_rate": 2e-5,
    "epochs": 100,
    "patience": 5,
    "dropout": 0.3,
    "weight_decay": 0.01,
    "class_weights": "inverse_frequency"
}
            </pre>

            <h3>B. Detailed Cohort Statistics</h3>

            <table>
                <thead>
                    <tr>
                        <th>Characteristic</th>
                        <th>Value</th>
                        <th>Notes</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Total patients</td>
                        <td>19,390</td>
                        <td>After MEDS processing</td>
                    </tr>
                    <tr>
                        <td>With adequate follow-up</td>
                        <td>17,956 (92.6%)</td>
                        <td>≥1 year after first event</td>
                    </tr>
                    <tr>
                        <td>Mixed care patterns</td>
                        <td>95%</td>
                        <td>Both inpatient and outpatient</td>
                    </tr>
                    <tr>
                        <td>Diabetes prevalence</td>
                        <td>25%</td>
                        <td>Any diabetes code</td>
                    </tr>
                    <tr>
                        <td>Median observation</td>
                        <td>63 years</td>
                        <td>From first to last event</td>
                    </tr>
                    <tr>
                        <td>Events per patient</td>
                        <td>Median: 847</td>
                        <td>All medical codes</td>
                    </tr>
                </tbody>
            </table>

            <h3>C. Outcome Definitions</h3>

            <div class="method-box">
                <h4>Death (All-cause mortality)</h4>
                <ul>
                    <li>Discharge disposition codes indicating death</li>
                    <li>Vital status indicators</li>
                    <li>Validated against institutional records</li>
                </ul>

                <h4>Myocardial Infarction</h4>
                <ul>
                    <li>ICD-9: 410.*</li>
                    <li>ICD-10: I21.*, I22.*</li>
                    <li>Includes STEMI and NSTEMI</li>
                </ul>

                <h4>Stroke</h4>
                <ul>
                    <li>ICD-9: 430-436.*</li>
                    <li>ICD-10: I60-I66.*</li>
                    <li>Includes ischemic and hemorrhagic</li>
                </ul>

                <h4>Heart Failure</h4>
                <ul>
                    <li>ICD-9: 428.*</li>
                    <li>ICD-10: I50.*</li>
                    <li>All subtypes included</li>
                </ul>
            </div>

            <h3>D. Code Availability</h3>
            <p>Source code and model weights will be made available at: <code>https://github.com/[to-be-released]/ASCEND</code></p>

            <h3>E. Ethical Considerations</h3>
            <p>This research was conducted using de-identified data in compliance with HIPAA regulations. The MEDS format ensures patient privacy while enabling reproducible research.</p>
        </section>

        <div class="footnote-content">
            <p><sup>1</sup> All performance metrics reported are from validation set evaluation during model training. Proper held-out test set evaluation is pending.</p>
            <p><sup>2</sup> The random prediction point framework is patent-pending (provisional application filed).</p>
        </div>

        <section class="references">
            <h2>References</h2>
            <ol>
                <li>World Health Organization. Cardiovascular diseases (CVDs) fact sheet. 2021.</li>
                <li>D'Agostino RB Sr, et al. General cardiovascular risk profile for use in primary care. Circulation. 2008;117(6):743-53.</li>
                <li>Goff DC Jr, et al. 2013 ACC/AHA guideline on the assessment of cardiovascular risk. Circulation. 2014;129(25 Suppl 2):S49-73.</li>
                <li>Goldstein BA, et al. Opportunities and challenges in developing risk prediction models with electronic health records data. J Am Med Inform Assoc. 2017;24(1):198-208.</li>
                <li>Vaswani A, et al. Attention is all you need. NeurIPS. 2017.</li>
                <li>Li Y, et al. BEHRT: Transformer for Electronic Health Records. Scientific Reports. 2020;10:7155.</li>
                <li>Rasmy L, et al. Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction. NPJ Digit Med. 2021;4:86.</li>
                <li>Savcisens G, et al. Using sequences of life-events to predict human lives. Nat Comput Sci. 2024;4:43-62.</li>
            </ol>
        </section>
    </div>
</body>
</html>
